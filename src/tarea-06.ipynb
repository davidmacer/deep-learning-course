{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Deep Learning\n",
    "\n",
    "# CentroGeo\n",
    "\n",
    "## David Martínez\n",
    "\n",
    "## 18 de junio del 2021"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# 1 Solve"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "1. Consider the unregularized perceptron update for binary classes with learning rate $\\alpha$. Show that using any value of $\\alpha$ is inconsequential in the sense that it only scales up the weight vector by a factor of $\\alpha$. Show that these results also hold true for the multiclass case. Do the results hold true when regularization is used?\n",
    "\n",
    "Solución.\n",
    "\n",
    "Según Charu [[1](https://drive.google.com/file/d/15ubCsLH85F8JIttNJcd-oNxFSppYaoY5/view?usp=sharing)], el algoritmo del perceptrón (implícitamente) utiliza una aproximación suavizada de el gradiente de la función objetivo:\n",
    "\n",
    "$$ \\nabla L_{\\textrm{smooth}} = \\sum_{(\\bf{\\bar{X}},y) \\in D} \\left( y - \\hat{y} \\right) \\bar{X}$$\n",
    "\n",
    "Aunque la función objetivo está definida sobre el total de datos de entrenamiento, el algoritmo de entrenamiento de las redes neuronales trabaja al ser alimentado por cada dato de entrada de la instancia $\\bar{X}$ en la red una por una (o en pequeños _batches_) para crar la predicción $\\bar{y}$. Los pesos son actualizados, basado en el valor de error $E(\\bar{X}) = (y - \\bar{y}$. Específicamente, cuando el dato $\\bar{X}$ es pasado a la red, el vector de pesos $\\bar{W}$ es actualizado como sigue:\n",
    "\n",
    "$$\\bar{W} \\leftarrow \\bar{W} + \\alpha(y - \\hat{y})\\bar{X}$$\n",
    "\n",
    "Podemos escribir entonces la actualización del descenso de gradiente en términos del error $E(\\bar{X}) = (y - \\hat{y})$ como sigue:\n",
    "\n",
    "$$\\bar{W} \\leftarrow \\bar{W} + \\alpha E(\\bar{X}) \\bar{X}$$\n",
    "\n",
    "En _mini-batch stochastic gradient descent_, las mencionadas actualizaciones de la ecuación anterior son implementadas aleatoreamente escogiendo un subconjunto $S$ de puntos de entrenamiento:\n",
    "\n",
    "$$\\bar{W} \\leftarrow \\bar{W} + \\alpha \\sum_{\\bar{X} \\in S} E(\\bar{X}) \\bar{X}$$\n",
    "\n",
    "Charu menciona que un interesante capricho de el perceptrón es que es posible establecer el _learning rate_ $\\alpha$ a 1, porque el _learning rate_ solamente escala los pesos.\n",
    "\n",
    "De la página de Stack Exchange [[2](https://datascience.stackexchange.com/questions/27898/normalizing-the-final-weights-vector-in-the-upper-bound-on-the-perceptrons-conv)] tomé la siguiente solución para dos clases:\n",
    "\n",
    "La salida $f$ del perceptrón es:\n",
    "\n",
    "$$f \\left( \\bar{\\theta} \\cdot \\bar{x} \\right) = \\left\\{ \\begin{array}{rcl} 1 & \\textrm{if} & \\bar{\\theta} \\cdot \\bar{x} > 0 \\\\ 0 & \\textrm{if} & \\bar{\\theta} \\cdot \\bar{x} \\le 0 \\end{array} \\right.$$\n",
    "\n",
    "donde $\\bar{\\theta}$ es el vector de pesos finales, $\\bar{\\theta} = \\bar{W}$.\n",
    "\n",
    "$\\bar{x} = (1, x_1, ..., x_n)$, donde $\\bar{x}$ es el vector de entrada.\n",
    "\n",
    "Se puede ver que la salida solo depende del signo del producto $\\bar{\\theta} \\cdot \\bar{x}$. Por lo tanto, la salida no cambiar si multiplicamos $\\bar{\\theta} \\cdot \\bar{x}$ por una constante positiva:\n",
    "\n",
    "$$f(\\bar{\\theta} \\cdot \\bar{x}) = f(c \\cdot \\bar{\\theta} \\cdot \\bar{x}) \\;\\ \\textrm{para todo} \\;\\ c>0.$$\n",
    "\n",
    "Se escoge $c = \\frac{1}{||\\theta||}$ y así obtenemos $f(c \\cdot \\bar{\\theta} \\cdot \\bar{x} = f(\\tilde{\\theta} \\cdot \\bar{x})$, donde $\\tilde{\\theta} = \\frac{\\bar{\\theta}}{||\\bar{\\theta}||}$ es el vector normalizado y se concluye que no existe pérdida de generalidad al suponer que $||\\bar{\\theta}|| = 1$.\n",
    "\n",
    "---\n",
    "\n",
    "Según Watt & Borhani [[3](https://jermwatt.github.io/machine_learning_refined/notes/7_Linear_multiclass_classification/7_2_OvA.html)], un conjunto de datos de múltiples clases $\\{(\\bf{x}_s,y_s)_{s=1}^S\\}$ consiste en $C$ distintas clases de datos. Usando el método de _One versus All Multiclass Classification_ (OvA) el problema es simple, ya que se reduce a una secuencia de problemas más pequeños y las etiquetas pueden verse como $y_s \\in {0,1,...,C-1}$. Queremos saber cómo distinguir entre cada clase de nuestro conjunto de datos del resto de las $C - 1$ clases. Desde esta perspectiva se ve factible aprender dos $C$ clases distintas en el conjunto de datos, con el clasificador $c^{th}$ entrenado para distinguir la clase $c^{th} de el resto de los datos. Este problema nos queda entonces:\n",
    "\n",
    "$$\\tilde{y}_s = \\left\\{ \\begin{array}{rcl} +1 & \\textrm{if} & y_s = c \\\\ -1 & \\textrm{if} & y_s \\ne c \\end{array} \\right.$$\n",
    "\n",
    "De esta manera, el problema de clasificar múltiples clases se convierte en varios problemas de clasificar dos clases. Eso prueba que el resultado anterior se mantiene para la clasificación de múltiples clases.\n",
    "\n",
    "---\n",
    "\n",
    "Cuando la regularización es implementada, [1] nos muestra un ejemplo de la versión regularizada de la ecuación vista arriba:\n",
    "\n",
    "$$\\bar{W} \\leftarrow \\bar{W}(1 - \\alpha \\lambda) + \\alpha \\sum_{\\bar{X} \\in S} E(\\bar{X}) \\bar{X},$$\n",
    "\n",
    "donde $\\lambda > 0$ es el parámetro de regularización, y nos menciona que el efecto práctico de este cambio es que una cantidad proporcional a $\\lambda w_i$ es extraida de la actualización del parámetro $w_i$.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "2. Let $(\\bf{x}_i, y_i)$ be a training instance, in which the observed value $y_i$ is predicted from the feature variables $x_i$. Show that the stochastic gradient-descent updates of the perceptron, Widrow-Hoff learning, SVM, and logistic regression are all of the form:\n",
    "\n",
    "    $$\\bf{w} \\leftarrow \\bf{w}(1 - \\alpha \\lambda) + \\alpha y \\left[ \\delta( \\bf{x}, y ) \\right] \\bf{x}$$\n",
    "\n",
    "    Here, the mistake function $\\delta(\\bf{x}, y)$ is $1 - y(\\bf{w}^T \\bf{x})$ for least-squares classification, an indicator variable for perceptron/SVMs, and a probability value for logistic regression. Assume that $\\alpha$ is the learning rate, and $y \\in \\{-1, +1 \\}$. Write the specific forms of $\\delta(\\bf{x}, y) in each case."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# 2. Write a code"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "1. The Widrow-Hoff learning rule is also referred to as _Adaline_, which is shortfor adaptive linear neuron. In machine learning, a model combination ensemble averages the scores of multiple models in order to create a more robust classification score. Discuss how you can approximate the averaging of an Adaline and logistic regression with a two-layer neural network. Discuss the similarities and differences of this architecture with an actual model combination ensemble when backpropagation is used to train it. Show how to modify the training process so that the final result is a fine-tuning of the model combination ensemble."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Referencias\n",
    "\n",
    "[1] https://drive.google.com/file/d/15ubCsLH85F8JIttNJcd-oNxFSppYaoY5/view?usp=sharing\n",
    "\n",
    "[2] https://datascience.stackexchange.com/questions/27898/normalizing-the-final-weights-vector-in-the-upper-bound-on-the-perceptrons-conv\n",
    "\n",
    "[3] https://jermwatt.github.io/machine_learning_refined/notes/7_Linear_multiclass_classification/7_2_OvA.html"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}